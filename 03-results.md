# Results

The contest attracted 294 participants who made 820 submissions using a variety of different methods (\nameref{s1-table}).

## Top four ranked approaches 

The winning solution (by a competitor from the United States with a degree in Physics from the University of Kansas) used a random forest algorithm. The algorithm combined predictions from 10 different trees trained on 60 derived data features. These features included a combination of low-peak and high-peak estimates for each gene pair and aggregate measures that are sensitive to systematic bias at the perturbagen, analyte, and plate level.

The second solution (by a competitor from Poland with a Master's degree in Computer Science from the Lodz University of Technology) used the Expectation-Maximization (EM) algorithm to fit a mixture of two log-normal models to the data for each gene pair. Instead of assuming a priori probability (the 2:1 ratio) of assignment to clusters, the algorithm learned it from the data by fitting a plate-wide distribution of cluster sizes. 
 
The third solution (by a competitor from India with a bachelor's degree in Computer Science) was a fast k-means algorithm with a random initialization procedure that tends to avoid local minima and is more robust to extreme outliers.
  
The fourth solution (by a competitor from Ukraine with a bachelor's degree in Computer Science from the Cherkasy National University) used a Convolutional Neural Network (CNN). This algorithm first filters and transforms the data into a 32-bin histogram for each pair of genes. Then, it uses the U-net architecture [@ronneberger2015u] to provide an adequate representation of the data. Then, it assigns each of the 32 bins to one of the two genes for each pair and predicts the median value. This final step uses two subnetworks with the same architecture with a mean squared error loss function (instead of the Spearman correlation used for scoring).

For each method, we generated the deconvolution data (DECONV) and the corresponding differential expression (DE) values. A docker container used for converting the deconvolution data to differential expression values can be downloaded from the Docker Hub [https://hub.docker.com/r/cmap/sig_2to4_tool](https://hub.docker.com/r/cmap/sig_2to4_tool).
Performance was then evaluated on the hold-out data. 

## Clustering by method and perturbagen type

First, we visually examined the quality of solutions using a two-dimensional t-SNE projection [@maaten2008visualizing], which was run once on each of the entire DECONV and DE datasets. 

The DECONV data clustered well by perturbagen type and less by algorithm type (\Fig{figure-tsne}), although with some notable commonalities in the predictions generated by similar approaches (\Fig{figure-tsne}, **d**). 
For example, the decision tree regressor (DTR) algorithms had similar 'footprints' in the projection, as do the k-means and Gaussian mixture model (GMM) algorithms. 

After the transformation to DE data, however, the t-SNE projection was more homogenous, with no particular clustering by perturbagen and algorithm type (\Fig{figure-tsne}, **c**). 
The lack of clustering in the DE data was reassuring given standard CMap analysis is performed on DE values.

## Deconvolution accuracy

Then, we assessed the deconvolution accuracy of each approach by looking at the genewise Spearman rank correlation between the UNI and DUO values. 

Based on the analysis of the benchmark, we expected: 1) a higher deconvolution accuracy in samples from shRNA experiments than in those from compounds (\Fig{figure-corr}, a), and 2) a higher deconvolution accuracy for genes in high bead-proportion relative to those in low bead-proportion (\Fig{figure-corr}, b). Intuitively, the deconvolution accuracy should be higher in more focused experiments and for genes with a higher number of beads.

On average across all samples, eight out of the top nine ranked approaches (90%) were significantly better than the benchmark (\Fig{figure-corr}, c). However, at a disaggregated level, improvements were significant for the 488 genes in low bead-proportion and not significant for those in high bead-proportion (\Fig{figure-corr}, d-g). Only the winning method achieved significant improvements in accuracy for genes in both high and low bead proportions.  

To evaluate the extent to which the winning algorithm outperformed the others, we ranked the top-nine algorithms by the average correlation metric for each gene (1 = highest, 9 = lowest). We then computed the percentage of genes for which a given algorithm was ranked first. The winner was ranked first for 30% of the genes, followed at some distance by the second-placed gaussian-mixture method (20%), and by the CNN method (13%). Thus, the top two submissions combined outperformed the rest for about half of the genes. Even so, all but a few algorithms were the best performers for at least 5% of the genes, suggesting some complementarity between these algorithms.

## Detection of extreme modulations

To evaluate the accuracy at the DE level, we used the detection accuracy of extreme modulations (genes notably up- or down-regulated by perturbation). We used the UNI data with DE values above a threshold as the ground truth; and we evaluated the detection accuracy of each solution by computing the corresponding AUC for each perturbagen type. 

The detection accuracy of extreme modulations was generally high for both shRNA and compound samples (AUC > 0.87 and AUC > 0.91,  respectively), with the competitors achieving notable improvements over the benchmark (\Fig{figure-auc}, a). Compared to the benchmark, the winning solution detected about 4,000 less extreme modulations (40,800 and 44,200, respectively), thus being more conservative. However, when we restricted the comparison to extreme modulations detected by UNI as well (thus controlling for detection precision), the winning solution detects about 1,500 more extreme modulations than the benchmark (27,100 and 25,600, respectively), representing a sensible 6% increase in “true” detections.^[These results are for the dataset with shRNA experiments for which we know the targeted genes. We expect similar results for the dataset of compound experiments.]

We complemented the above analysis by using targeted gene knockdown (KD) experiments as the ground truth for a subset of data. These are experiments in which a landmark gene was targeted by an shRNA, and hence we expect to observe a significant decrease in expression for the targeted gene. We evaluated the KD detection accuracy of each solution by computing the corresponding percentage of successful KD genes identified or recalled by the algorithm (defining a successful KD as one gene in which the DE value and the corresponding gene-wise rank in the experiment are less than a given threshold, -2 and 10 respectively). We computed the percentage recall for the UNI data as well, which yielded an estimate of the maximum achievable recall of 0.80. Relative to this level, nearly all algorithms achieved a good recall and precision, with values that were higher than the benchmark solution for all but two methods (\Fig{figure-auc}, b). 

## Reduced variation across replicate samples

To evaluate the reproducibility of the results, we leveraged the several replicate samples for each shRNA and compound experiment in our dataset (about 4 and 10 replicates, respectively). We computed the mean gene-wise coefficient of variation (CV) for each method, which is a measure of inter-replicate variability computed as the average ratio between the interquartile range and the median value  across all the replicates. Using this measure, we found all solutions achieved significant improvements over the benchmark (\Fig{figure-inter}); and the winning method, which was the most accurate on average, also achieved the lowest inter-replicate variation overall.

## Computational speed

The speed improvements over the benchmark were substantial. While dpeak took about 4-5 minutes per plate, the  fastest algorithm took as little as 5 seconds per plate (more than a 60x speedup compared to the benchmark) and the slowest was well below one minute. These speed improvements are not directly attributable to the use of multiple cores, since both the benchmark and contestant algorithms leverage multi-core techniques. We observed no particular trade-off between speed and accuracy.

## Ensembles

Lastly, we assessed the performance of ensembles combining the predictions of different computational methods by taking the median value across all 10 predictions (including the benchmark). By focusing on the subset of the data with shRNA experiments (ignoring the data with compound experiments), the performance in both Spearman correlation and the AUC metrics of the ensemble tended to increase with the number of models involved (\Fig{figure-ensembles}). However, the maximum performance in both metrics tended to plateau (or even decrease) after combining the results of 3 or more models. This result suggested limited gains from having ensembles, although it may be worth exploring more sophisticated aggregation approaches.
