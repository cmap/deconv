# Methods

\Fig{figure-methods} shows a schematic illustration of the contest's main features including a problem statement, the data, and the scoring function used to evaluate submissions. 

The contest's problem statement described the deconvolution task and the current solution in detail. The key insight was that the typical distribution of measurements for each gene pair has two peaks, the size of which should reflect the relative proportion of the genes in the sample. L1000 takes full advantage of this statistical property by: (1) pairing genes optimally, trying to maximize the average difference in their expression levels, and (2) mixing genes in a 2:1 proportion, which enables the correct assignment of peaks to each gene within the pair (see @subramanian2017next for details). Then, it uses a deconvolution approach to partition the composite measurements for each profile into $k$ clusters (by minimizing the within-cluster sum of squares) and associate the largest (smallest) cluster to the gene with higher (lower) bead proportion, assigning the cluster's median value to the corresponding gene.

The datasets consisted of six 384-well perturbagen plates, each containing mutually exclusive sets of compound and shRNA treatments (\nameref{s1-table} and \nameref{s2-table} show a complete list). Multiple cell lines and perturbagen were used to avoid any potential over-fitting. The compound and shRNA  plates were arbitrarily grouped into pairs, and to avoid any potential 'information leakage' each pair was profiled in a different cell line. The resulting lysates were amplified by Ligation Mediated Amplification (LMA, @subramanian2017next). The amplicon was then split and detected in both UNI and DUO detection modes, resulting in three pairs of data generated under comparable circumstances.  The training data was available for all the contestants to develop and validate their solutions offline. The testing data was used for submission evaluation during the contest and to populate a live leaderboard. The holdout data was used for final evaluation, thus guarding against over-fitting. Prizes were awarded based on performance on the holdout dataset. 

The scoring function combined measures of accuracy and computational speed (\nameref{s1-appendix}). The accuracy metric was the product of two different metrics. The first was the average genewise Spearman's rank correlation between the deconvoluted expression values and the ground truth. The second was the Area Under the receiver operating characteristic Curve (AUC) in the prediction of extremely modulated genes. Speed was measured by executing each submission on comparable multi-core machines, thus allowing competitors to employ multithreading techniques, and the corresponding score was the average runtime in units of the benchmark runtime.


<!-- (prize split: 80, 60, 40, 20, 10, 8, 6, 4, and 1 hundred dollars). -->