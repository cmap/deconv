
Introduction
============

<!-- 
A major limitation of multianalytes assays is their limited number of available analyte types. 
In the context of RNA profiling, the CMap group has developed a framework that integrates statistical analysis with traditional multianalyte methods to infer differential expressions for multiple genes from the same analyte type. 
We report the results of an open innovation competition that impvored upon the state-of-the-art by integrating machine-learning techniques to address the deconvultion problem. 
 -->

<!--
Over the last decade, the ability to analyze multiple analytes simultaneously from the same biological sample has contributed to creating large perturbational datasets that are essential to accelerate the discovery of novel therapeutics. However, a fundamental limitation of traditional multianalyte assays lies in the restricted extent and type of available analytes
-->

Over the last decade, technological advances in multiplexed, high-throughput experimental systems have made it possible to generate large perturbational datasets which in turn have helped accelerate therapeutic discovery. A large proportion of these technologies rely on using multiple analytes (or 'sensors') to measure biological signals. These assays are extremely powerful but in some applications are limited by the number of unique analytes they can detect.^[For example, Luminex's most advanced platform, called FLEXMAP 3D, can measure simultaneously a maximum of 500 bead types for an equal number of genes or proteins from a small sample.]

This limitation is more prominent for gene-expression profiling, given the high number of genes involved. Within this context, the Connectivity Map (CMap) has developed an assay, called L1000, that integrates traditional multianalyte detection methods and statistical analyses to simultaneously measure the expression for multiple genes using the same analyte type, thus multiplying the capacity of existing technologies [@subramanian2017next].

<!-- The algorithm D-peak is based on k-means algorithm, a general and flexible tool to conduct non-parametric regression that is very popular in biology, as well as in many other fields.  -->
<!-- The current algorithm works well, but has some limitations.  -->
<!-- > OLD Multianalyte methods for high-throughput gene-expression profiling have found widespread application in biology. The extent of these applications, however, tend to be limited by the type and number of available analytes, which typically results in prohibitive costs for big data generation. Using an assay called L1000 that measures the mRNA transcript abundance of 978 "landmark" genes from human cells, the Connectivity Map (CMap) group at the Broad Institute has developed a novel approach that matches pairs of genes to the same analyte type, or bead, to double the count of profiled genes, thus lowering greatly costs [@subramanian2017next].  -->

A central component of this approach is the computational deconvolution of gene expression signals from multiple genes measured using the same analyte. Similar deconvolution problems are ubiquitous in biology and several solutions have been proposed in a variety of different contexts. Examples include algorithms to identify cell type–specific gene expression differences in complex tissues [@shen2010cell] or dynamic changes in cell populations [@lu2003expression], or ways to discover the target proteins of small molecules [@terstappen2007target].

CMap’s current deconvolution approach, called dpeak, is based on the k-means clustering algorithm, which is a flexible  unsupervised learning procedure widely used in biology, as well as in many other fields. 
This approach automatically partitions a set of gene-expression measurements into $k$ clusters by minimizing the within-cluster sum of squares. It then assigns the clusters to each gene within the sample (see @subramanian2017next for the details). This approach works well in practice but has several limitations; it tends to split clusters incorrectly when the distributions are not reasonably well separated, it is sensitive to outliers, and it is computationally demanding (an efficient k-means algorithm, such as Lloyd's, has a running time that scales as $O(kn)$ where $n$ is the number of observations and $k$ the number of clusters).

Motivated by recent successes in the use of machine learning techniques in biology, we hypothesized better deconvolution approaches could likely be developed. To test this hypothesis, we generated a novel experimental dataset of the response of approximately 1,000 genes to 122 different perturbagens (shRNA and compounds) within 4 to 10 replicates. Using the L1000 platform, we varied the detection mode for acquiring the data between two genes per analyte type (DUO) and one gene per analyte type (UNI). We then used the data to run an open innovation competition (as described in @lakhani2013prize and @blasco2019advancing) where we solicited different solutions to the deconvolution problem by offering cash incentives to competitors and we assessed the accuracy of the elicited approaches using the UNI data as the ground truth.

The top approaches included very popular machine-learning methods, such as Random Forests and Convolutional Neural Networks (CNNs), as well as more traditional Expectation-Maximization (EM) approaches based on Gaussian mixtures. Overall, the results of the challenge enabled us to perform a cost-effective comparison of different methods under nearly identical conditions, which we report below. 

<!-- 
Based on this comparison, we found that the competitors' methods achieved significant improvements in accuracy over the k-means benchmark with respect to gene expression values, improved detection of extreme modulations, including an improved ability to detect target knockdowns in shRNA experiments; they yielded more consistent predictions across replicates (a smaller inter-replicate variability), thus leading to more reliable outcomes overall. Additionally, we evaluated the computational speed of all the approaches. Traditional parametric methods, such as the EM, achieved 60x speedup compared to the benchmark, without losing on the accuracy. Machine-learning methods, such as Random Forests, achieved greater accuracy but achieved smaller improvements in terms of speed.
 -->

<!--  of the pair, using additional information about differences in the bead proportions of the genes (within each pair, one gene has a higher proportion of beads than the other). -->

<!-- mean of the largest cluster to the gene in higher proportion and the mean value of the second largest cluster to the gene in lower proportion -->


<!-- 
As a research tool to test for alternative solutions, we used an open innovation competition [@lakhani2013prize; @blasco2019advancing]. In this paper, we report the outcomes of the competition, which successfully engaged a variety of competitorscomputer scientist, software developers and bioinformatics in the problem, resulting in a cost-effective exploration of competing approaches (random forest, gaussian mixture models, and convolutional nets) that would have been otherwise prohibitive.
 -->

<!-- Testing for alternative methods would have required substantial resources to experiment with these alternative approaches (more than what already done) and to adapt new to our data. Moreover, impossible an exhaustive search for all available approaches to try; and the combination of these different approaches.  -->


<!-- 
Shen-orr et al. (2010). Gene expression data from multiple cell-types. The problem is to quantify cell-type frequency "then deconvolve and compare cell type-specific average expression profiles for groups of mixed tissue samples." One approach is "deconvolution to be linear"
 -->

<!-- Broadly speaking, the problem is to estimate the density $f$ of a random variable $X$ based on $n$ observations from $Y = X + \epsilon$, where $\epsilon$ is a measurement error based on a possibly unknown distribution.  (Fan, 1991) -->

<!-- The solution adopted by CMap was a KNN [explain]. This is a standard technique implemented in xxx that gives a good level of accuracy [xxx] and reasonably fast computation time (xxx with the current Matlab implementation). -->




<!-- 
## Related literature 
@musa2017review review of cmap. 
@down2008bayesian A Bayesian deconvolution strategy for immunoprecipitation-based DNA methylome analysis
@liu2015compound used a fuzzy c-means Gaussian Mixture Model (GMM) to process raw L1000 data, showing better performance compared to KNN. This method is described below: 
@zhong2012gene Gene expression deconvolution in linear space
@hunt1971deconvolution one of the first deconv? 
@preibisch2014efficient Efficient Bayesian-based multiview deconvolution
 -->

<!-- 
> To deconvolute such overlapped peaks, we assumed that the fluorophore intensities of each analyte type (corresponding to a specific mRNA type) had a Gaussian distribution. The distribution of the mixture of analytes GeneH(i) and GeneL(i) corresponding to the expression levels of GeneH and GeneL, respectively, should be subject to a bimodal Gaussian distribution, with the proportion of 1.25 to 0.75. We initialized the estimations of the two Gaussian distributions using buzzy c-means clustering [11] and estimated the GMM parameters using the Nelder-Mead method [12]. Thus, the overlapped peaks were deconvoluted as the two estimated Gaussian peaks and the expression levels of the two genes sharing the same analyte were extracted. Mathematical details are included in the Supplementary Methods (the GMM model).
 -->


