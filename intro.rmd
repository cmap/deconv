
Introduction
============

<!-- 
Outline:
  - Traditional methods may be suboptimal, potentially limiting new discoveries
  - ML methods have potential but presents challenges in validation, adaptation, and identification of the best approach
  - For validation e profiled 6 plates worth of data with 122 perturbagens (shRNA and compounds)
-->

Deconvolution problems are ubiquitous in many areas of science. In the context of biomedical research, the problem often consists of acquiring gene expression levels from distinct populations (cell types, tissues, and genes) using random composite measurements (e.g., fluorescence intensity of a single analyte, or sensor). Common examples include the efficient generation of transcriptomic profiles [@subramanian2017next; @cleary2017efficient], measuring cell-type specific differential gene expression from mixed samples [@shen2010cell; @zhong2012gene; @newman2015robust; @zaitsev2019complete], profiling single-cell gene expression in heterogeneous tissues [@deng2019scalable], and tracking cell growth in dynamically evolving populations [@lu2003expression]; but similar problems arise also in many other related contexts, such as imaging [e.g., multiview integration, @preibisch2014efficient]. In all these situations, researchers must deconvolute the composite data to identify and isolate measurements from each population.Â 

Existing deconvolution approaches work well in many specific settings, but might be suboptimal to the increasing availability of biological data. Machine learning techniques can potentially improve the current methods to identify and isolate measurements from distinct populations. A typical advantage of these techniques is the ability to capture automatically complicated patterns that can be hard to model otherwise; especially in complex and massive datasets as those frequently used in biomedical research However, introducing these new machine-learning techniques in the field presents several challenges; some of which are validation, adaptation to complex datasets, and identification of the best machine-learning approaches to specific problems.

Here we describe how we addressed these challenges in the context of the deconvolution of gene-specific gene expression signals from mixtures of multiple genes. Using the L1000 gene-expression assay [@subramanian2017next], we generated a novel experimental dataset with the transcriptional response of approximately 1,000 genes to 122 different perturbagens (shRNA and compounds) with several replicates for a total of over 2,200 gene expression experiments. For each experiment, we acquired the L1000 data under two different detection methods. In the first, called UNI, we measured the expression level of each gene directly by detecting one gene per analyte type; and in the second, called DUO, we acquired a mixture of the gene expression level of two genes by coupling each analyte type to two different genes. This provided ground-truth data that enabled us to evaluate empirically different deconvolution methods under nearly identical conditions.

Leveraging this data, we then explored the use of different machine learning approaches through an open innovation competition based on our previous work [@lakhani2013prize; @blasco2019advancing]. We run the contest on Topcoder, a popular crowdsourcing platform. The contest challenged participants to use the novel dataset to improve the deconvolution algorithm utilized by the L1000 platform. The contest drew about 300 competitors from across the globe and resulted in a diverse number of machine-learning approaches. The top approaches included machine-learning methods, such as Random Forests and Convolutional Neural Networks (CNNs), as well as more traditional Gaussian-mixture models. These approaches significantly performed better than the L1000 benchmark in various measures of accuracy and computational speed, and likely have application beyond gene expression.

As we discuss in more detail below, results showed that a Random Forest approach, a popular machine-learning technique, achieved (i) the highest "global" correlation between UNI and DUO data, (ii) the lowest inter-replicate variability and (iii), compared to the benchmark, was able to detect more than a thousand additional differentially-expressed genes, while improving the detection precision at the same time. This provides evidence of the tremendous potential of using machine-learning approaches for deconvolution methods in biology. 

<!-- 
Here we describe how we addressed these challenges in the context of the deconvolution of gene-specific expression data using the L1000 gene expression assay [@subramanian2017next]. Using L1000, we generated a novel experimental dataset with the transcriptional response of approximately 1,000 genes to 122 different perturbagens (shRNA and compounds) with several replicates for each. We profiled these data from separate and mixed samples. used for the evaluation of different methods. We then describe the results of an open innovation competition [@lakhani2013prize; @blasco2019advancing] using the generated dataset to improve the deconvolution methods on L1000 data. The contest drew competitors from across the globe and resulted in a diversity of machine-learning approaches that significantly improved over the L1000 benchmark and likely have application beyond gene expression. 
 -->

 


<!-- 
Traditional deconvolution methods have a long history in biology, as well as in many other areas of science [ref]. 
While traditional methods seem to work well in specific applications in biology, they have several limitations as well [ref]. The recent success of machine learning in many pattern recognition tasks suggests that these methods could be effective in addressing deconvolution problems as well. This is because of the ability of ML techniques to discover patterns in complex and massive datasets of the size of many current datasets in biomedical research, such as the Connectivity Map (CMap). However, entering these new machine learning techniques in the field presents several challenges, including validation, adaptation to specific datasets, and identification of the best ML approaches to the problem.
 -->
  
<!-- 
We address theis problem in the context of xxxx. 
    - For evaluation, we generated a unique dataset of gene-expression data with ground truth 
      (which is now publicly available)  
    - To explore different approaches we used an open contest ($20,000 prize pool)    
-->
 
