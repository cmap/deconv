
Introduction
============

<!-- 
  - Traditional methods may be suboptimal, potentially limiting new discoveries
  - ML methods have potential but presents challenges in validation, adaptation, and identification of the best approach
  - For validation e profiled 6 plates worth of data with 122 perturbagens (shRNA and compounds)
-->


<!-- 
A major limitation of multianalytes assays is their limited number of available analyte types. 
In the context of RNA profiling, the CMap group has developed a framework that integrates statistical analysis with traditional multianalyte methods to infer differential expressions for multiple genes from the same analyte type. 
We report the results of an open innovation competition that impvored upon the state-of-the-art by integrating machine-learning techniques to address the deconvultion problem. 
 -->

<!--
Over the last decade, the ability to analyze multiple analytes simultaneously from the same biological sample has contributed to creating large perturbational datasets that are essential to accelerate the discovery of novel therapeutics. However, a fundamental limitation of traditional multianalyte assays lies in the restricted extent and type of available analytes
-->

Biomedical researchers frequently leverage the performance of multiplex assays by using a single analyte, or sensor, to measure multiple signals from distinct populations (cell types, tissues, and genes). Common examples include measuring cell-type specific differential gene expression from mixed samples [@shen2010cell], profiling single-cell gene expression in heterogeneous tissues [@deng2019scalable], and tracking cell growth in dynamically evolving populations [@lu2003expression]; but similar occurrences arise also in many other related contexts, such as imaging [e.g., multiview integration, @preibisch2014efficient]. In all these situations, researchers must deconvolute the composite data to identify and isolate measurements from each population.Â 

Traditional deconvolution methods work well in specific settings but have several limitations as well [ref]. Motivated by the recent success of machine learning in pattern recognition tasks, we hypothesized that these more-recent techniques could be effective in addressing deconvolution problems as well. Compared to more traditional methods, a key advantage of machine learning techniques, such as Neural networks or Random Forests, is that the learning algorithm automatically captures nonlinear patterns that are hard to model otherwise, especially in complex and massive datasets as those frequently used in biomedical research. However, entering these new machine learning techniques in the field presents several challenges. Some of which is validation, adaptation to specific datasets, and identification of the best machine-learning approaches to specific problems.

Here we describe how we addressed these challenges in the context of the deconvolution of gene-specific differential gene expression from samples containing a mixture of multiple genes. Using the L1000 gene-expression assay [@subramanian2017next], we generated a novel experimental dataset with the transcriptional response of approximately 1,000 genes to 122 different perturbagens (shRNA and compounds) with several replicates for a total of over 2,200 gene expression experiments. For each experiment, half of the data were obtained by using one single analyte to measure the differential gene expression of individual genes from a mixed sample of two genes (DUO data); and the other half was obtained by using one analyte per each gene (UNI data). This enabled us to evaluate empirically different deconvolution methods under nearly identical conditions.

Based on these data, we then explored different machine learning approaches through an open innovation competition [@lakhani2013prize; @blasco2019advancing]. We run the contest on a crowdsourcing platform (Topcoder) which is popular in the United States. The contest challenged participants to use the novel dataset to improve the deconvolution algorithm utilized by the L1000 platform. The contest drew competitors from across the globe and resulted in a diversity of machine-learning approaches. The top approaches included machine-learning methods, such as Random Forests and Convolutional Neural Networks (CNNs), as well as more traditional Gaussian-mixture models. These approaches significantly improved over the L1000 benchmark in various measures of accuracy and computational speed, and likely have application beyond gene expression.

Results show that the winning approach based on a random forest, a popular machine-learning technique, achieved (i) the highest "global" correlation between UNI and DUO data, (ii) the lowest inter-replicate variability and (iii), compared to the benchmark, was able to detect more than a thousand additional differentially-expressed genes, while improving the detection precision at the same time. This provides evidence of the tremendous potential of using machine-learning approaches for deconvolution methods in biology. 

<!-- 
Here we describe how we addressed these challenges in the context of the deconvolution of gene-specific expression data using the L1000 gene expression assay [@subramanian2017next]. Using L1000, we generated a novel experimental dataset with the transcriptional response of approximately 1,000 genes to 122 different perturbagens (shRNA and compounds) with several replicates for each. We profiled these data from separate and mixed samples. used for the evaluation of different methods. We then describe the results of an open innovation competition [@lakhani2013prize; @blasco2019advancing] using the generated dataset to improve the deconvolution methods on L1000 data. The contest drew competitors from across the globe and resulted in a diversity of machine-learning approaches that significantly improved over the L1000 benchmark and likely have application beyond gene expression. 
 -->

 


<!-- 
Traditional deconvolution methods have a long history in biology, as well as in many other areas of science [ref]. 
While traditional methods seem to work well in specific applications in biology, they have several limitations as well [ref]. The recent success of machine learning in many pattern recognition tasks suggests that these methods could be effective in addressing deconvolution problems as well. This is because of the ability of ML techniques to discover patterns in complex and massive datasets of the size of many current datasets in biomedical research, such as the Connectivity Map (CMap). However, entering these new machine learning techniques in the field presents several challenges, including validation, adaptation to specific datasets, and identification of the best ML approaches to the problem.
 -->
  
<!-- 
We address theis problem in the context of xxxx. 
    - For evaluation, we generated a unique dataset of gene-expression data with ground truth 
      (which is now publicly available)  
    - To explore different approaches we used an open contest ($20,000 prize pool)    
-->
 
## Methods [new methods section]
 
<!-- --- The L1000 ---  -->
L1000 is a high-throughput assay that lowers (same reproducivility of RNA-seq) by focusing on a reduced representations of gene  expression (focusing on 1000 "landmark" genes from human cells);  measurements are made using the 500 colors of Luminex beads such that two transcripts are identified by a single bead color.  L1000 matches pairs of genes to the same analyte type, or bead, to double the count of profiled genes in a single experiment, thus lowering greatly costs [@subramanian2017next]. A central component of this approach is the computational deconvolution of gene expression signals from multiple genes measured using the same analyte. And has contributed to massive scale-up of Connectivity Map (lamb et al.), from its initial xxx profiles to the current 1.3 million L1000 profiles.  


<!-- Connectopedia: L1000 is a high-throughput gene expression assay that measures the mRNA transcript abundance of 978 "landmark" genes from human cells. (The "L" in L1000 refers to the Landmark genes measured in the assay.) Measurements are made using the 500 colors of Luminex beads such that two transcripts are identified by a single bead color. We also measure expression of 80 control transcripts, chosen for their invariant expression across cell states, as well as the 978 Landmark genes. -->

<!-- within the context of RNA profile, the Connectivity Map (CMap) has developed an assay, called L1000, that integrates traditional multianalyte detection methods and statistical analyses to simultaneously measure the expression of multiple genes using the same analyte type, thus multiplying the capacity of existing technologies [@subramanian2017next]. -->

<!-- 
@cleary2017efficient proposes to use "compressed sensing to use low-level measurements or composite signals (from multiple genes) to recover high-level... 
@deng2019scalable
@hie2019efficient
such as to measure differential gene expression for each gene in mixed cell-type samples [@shen2010cell], 
for studying the state of cells and tissues in response to perturbations
 -->

To measure two different genes by a single bead type, L1000's deconvolution approach, called dpeak, is based on the k-means clustering algorithm. This is a method for cluster analysis, originally from signal processing [@lloyd1982least], that is popular in biology. The approach aims to partition a set of measurements (fluorescence intensity for each bead type) into $k$ clusters by minimizing the within-cluster sum of squares. Differentially expressed genes should have a distribution of measurements with two peaks; and the size of each peak will be a reflection of the proportion of beads used xxxx. By mixing genes in a 2:1 proportion,  the algorithm can tus assigns the clusters to each gene within the sample (see @subramanian2017next for the details). 

The dpeak approach works well in practice but has several limitations; it tends to split clusters incorrectly when the distributions are not reasonably well separated, it is sensitive to outliers, and it is computationally demanding.^[An efficient k-means algorithm, such as Lloyd's, has a running time that scales as $O(kn)$ where $n$ is the number of observations and $k$ the number of clusters.]

Motivated by recent successes with machine learning techniques in biology, we hypothesized better deconvolution approaches that could likely be developed. To test this hypothesis, we generated a novel experimental dataset of the response of approximately 1,000 genes to 122 different perturbagens (shRNA and compounds) within 4 to 10 replicates. Using the L1000 platform, we varied the detection mode for acquiring the data between two genes per analyte type (DUO) and one gene per analyte type (UNI). We then used the data to run an open innovation competition (as described in @lakhani2013prize and @blasco2019advancing) where we offered cash incentives for different solutions for the deconvolution problem. We assessed the accuracy of these different approaches using the UNI data as the ground truth.


<!-- 
Based on this comparison, we found that the competitors' methods achieved significant improvements in accuracy over the k-means benchmark with respect to gene expression values, improved detection of extreme modulations, including an improved ability to detect target knockdowns in shRNA experiments; they yielded more consistent predictions across replicates (a smaller inter-replicate variability), thus leading to more reliable outcomes overall. Additionally, we evaluated the computational speed of all the approaches. Traditional parametric methods, such as the EM, achieved 60x speedup compared to the benchmark, without losing on the accuracy. Machine-learning methods, such as Random Forests, achieved greater accuracy but achieved smaller improvements in terms of speed.
 -->

<!--  of the pair, using additional information about differences in the bead proportions of the genes (within each pair, one gene has a higher proportion of beads than the other). -->

<!-- mean of the largest cluster to the gene in higher proportion and the mean value of the second largest cluster to the gene in lower proportion -->


<!-- 
As a research tool to test for alternative solutions, we used an open innovation competition [@lakhani2013prize; @blasco2019advancing]. In this paper, we report the outcomes of the competition, which successfully engaged a variety of competitorscomputer scientist, software developers and bioinformatics in the problem, resulting in a cost-effective exploration of competing approaches (random forest, gaussian mixture models, and convolutional nets) that would have been otherwise prohibitive.
 -->

<!-- Testing for alternative methods would have required substantial resources to experiment with these alternative approaches (more than what already done) and to adapt new to our data. Moreover, impossible an exhaustive search for all available approaches to try; and the combination of these different approaches.  -->


<!-- 
Shen-orr et al. (2010). Gene expression data from multiple cell-types. The problem is to quantify cell-type frequency "then deconvolve and compare cell type-specific average expression profiles for groups of mixed tissue samples." One approach is "deconvolution to be linear"
 -->

<!-- Broadly speaking, the problem is to estimate the density $f$ of a random variable $X$ based on $n$ observations from $Y = X + \epsilon$, where $\epsilon$ is a measurement error based on a possibly unknown distribution.  (Fan, 1991) -->

<!-- The solution adopted by CMap was a KNN [explain]. This is a standard technique implemented in xxx that gives a good level of accuracy [xxx] and reasonably fast computation time (xxx with the current Matlab implementation). -->

<!-- 
## Related literature 
@musa2017review review of cmap. 
@down2008bayesian A Bayesian deconvolution strategy for immunoprecipitation-based DNA methylome analysis
@liu2015compound used a fuzzy c-means Gaussian Mixture Model (GMM) to process raw L1000 data, showing better performance compared to KNN. This method is described below: 
@zhong2012gene Gene expression deconvolution in linear space
@hunt1971deconvolution one of the first deconv? 
@preibisch2014efficient Efficient Bayesian-based multiview deconvolution
 -->

<!-- 
> To deconvolute such overlapped peaks, we assumed that the fluorophore intensities of each analyte type (corresponding to a specific mRNA type) had a Gaussian distribution. The distribution of the mixture of analytes GeneH(i) and GeneL(i) corresponding to the expression levels of GeneH and GeneL, respectively, should be subject to a bimodal Gaussian distribution, with the proportion of 1.25 to 0.75. We initialized the estimations of the two Gaussian distributions using buzzy c-means clustering [11] and estimated the GMM parameters using the Nelder-Mead method [12]. Thus, the overlapped peaks were deconvoluted as the two estimated Gaussian peaks and the expression levels of the two genes sharing the same analyte were extracted. Mathematical details are included in the Supplementary Methods (the GMM model).
 -->


