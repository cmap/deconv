# Methods

<!-- L1000's measurements are made using the 500 colors of Luminex beads such that two transcripts are identified by a single bead color, to double the count of profiled genes in a single experiment. It follows that a central component of the L1000 assay is the computational deconvolution of gene-specific expression values from composite signals obtained by using the same analyte.  -->

The current L1000's deconvolution approach, called d-peak, is based on the k-means clustering algorithm. This is a popular method for cluster analysis, originally from signal processing [@lloyd1982least]. This approach partitions a set of measurements (fluorescence intensity for each bead type) into $k$ clusters by minimizing the within-cluster sum of squares. Differentially expressed genes should have a distribution of measurements with two peaks, and the size of each peak will be a reflection of the proportion of beads per gene. Therefore, by mixing genes in a 2:1 proportion, the algorithm can isolate and assign the clusters to each gene within the sample [see @subramanian2017next for the details].

Potential limitations of this approach are well known: it tends to split clusters incorrectly when the distributions are not reasonably well separated; it is sensitive to outliers; and it is computationally demanding. An efficient k-means algorithm, such as Lloyd's, has a running time that scales as $O(kn)$ on a dataset with $n$ observations and $k$ clusters.

<!-- We hypothesized that better deconvolution approaches could likely be developed by adapting existing machine learning techniques to L1000 data. To test this hypothesis, we generated a novel experimental dataset of the response of approximately 1,000 genes to 122 different perturbagens (shRNA and compounds) within 4 to 10 replicates. Using the L1000 platform, we varied the detection mode for acquiring the data between two genes per analyte type (DUO) and one gene per analyte type (UNI). We then used the data to run an open innovation competition  [@lakhani2013prize; @blasco2019advancing] where we challenged competitors to provide different solutions for the deconvolution problem, as we describe below. -->

We designed an open innovation competition to explore alternative deconvolution approaches. We ran the competition on the Topcoder platform (Wipro, India) for a total of 21 days. A prize purse of $23,000 in cash was offered to competitors as incentive to be divided among the top 9 submissions (prize split: 80, 60, 40, 20, 10, 8, 6, 4, and 1 hundred dollars).

The data consisted of six 384-well perturbagen plates, each containing mutually exclusive sets of compound and short-hairpin (shRNA) treatments (see \nameref{s1-table.} and \nameref{s2-table.} for a complete list of the perturbagens). Multiple treatment types were used to avoid potentially over-fitting to anyone. The compound and shRNA perturbagen plates were arbitrarily grouped into pairs, and to avoid any potential 'information leakage' each pair was profiled in a different cell line. The resulting lysates were amplified by Ligation Mediated Amplification (LMA, @subramanian2017next). The amplicon was then split and detected in both UNI and DUO detection modes, resulting in three pairs of data generated under comparable circumstances. 

The generated data was then split into training, testing, and holdout subsets. The training data was available for all the contestants to develop and validate their solutions offline. The testing data was for submission evaluation during the contest and to populate a live leaderboard. The holdout data was for submission final evaluation evaluate, thus guarding against over-fitting. Prizes were awarded based on performance on the holdout dataset.

Submission evaluation was based on a scoring function (Figure 1) to incentivize improvements in accuracy and computational speed. This function combined two different accuracy metrics and a measure of computational speed: the average Spearman rank correlation between the values and the ground truth for each gene; the average Area Under the receiver operating Curve (AUC) in the prediction of extreme modulated genes; and the runtime in seconds per plate. (See \nameref{s1-appendix} for more details).

