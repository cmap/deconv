# Methods

We provided competitors with a problem statement, access to training and testing data, and a well-defined scoring function. \Fig{figure-methods} shows a schematic illustration of these three elements.  

The problem statement described L1000's deconvolution task and the current solution. The key insight was that the distribution of the composite measurements of two differentially expressed genes should have two peaks and the size of each peak should reflect the proportion of measurements for the corresponding gene. L1000 takes full advantage of this fact by pairing genes optimally, trying to maximize the average difference in their expression levels, and by mixing genes in a 2:1 proportion to enable the assignment of the correct expression levels to each gene within each pair [see @subramanian2017next for the details]. Then it uses the dpeak deconvolution algorithm to detect the peaks within the composite distribution. This procedure is based on a k-means clustering algorithm that partitions the composite measurements for each profile into $k$ clusters by minimizing the within-cluster sum of squares. It then associates the largest cluster to the gene with higher bead proportion, and the smallest cluster to the gene with lower bead proportion, assigning their median values to the corresponding gene.

The training and testing datasets are publicly available (\nameref{s1-data}). These data consisted of six 384-well perturbagen plates, each containing mutually exclusive sets of compound and short-hairpin (shRNA) treatments (\nameref{s1-table} and \nameref{s2-table} show a complete list of the perturbagens). Multiple cell lines and perturbagen were used to avoid potentially over-fitting to any one. The compound and shRNA perturbagen plates were arbitrarily grouped into pairs, and to avoid any potential 'information leakage' each pair was profiled in a different cell line. The resulting lysates were amplified by Ligation Mediated Amplification (LMA, @subramanian2017next). The amplicon was then split and detected in both UNI and DUO detection modes, resulting in three pairs of data generated under comparable circumstances.  The training data was available for all the contestants to develop and validate their solutions offline. The testing data was used for submission evaluation during the contest and to populate a live leaderboard. The holdout data was for final evaluation, thus guarding against over-fitting. Prizes were awarded based on performance on the holdout dataset. 

The scoring function combined measures of accuracy and computational speed (\nameref{s1-appendix}). The accuracy metric was the product of two different metrics. The first was the average genewise Spearman's rank correlation between the deconvoluted expression values and the ground truth. The second was the Area Under the receiver operating characteristic Curve (AUC) in the prediction of extremely modulated genes. Speed was measured by executing each submission on comparable multi-core machines, thus allowing competitors to employ multithreading techniques, and the corresponding score was the average runtime in units of the benchmark runtime.

The contest lasted 21 days. A prize purse of $23,000 in cash was offered to competitors as an incentive to be divided among the top 9 submissions.


<!-- (prize split: 80, 60, 40, 20, 10, 8, 6, 4, and 1 hundred dollars). -->