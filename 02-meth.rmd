# Methods

We provided competitors with a problem statement, access to training and testing data, and a well-defined scoring function. \Fig{figure-methods} shows a schematic illustration of these three elements.  

The problem statement of the challenge described L1000's deconvolution task and the current solution. The key insight was that the distribution of the composite measurements of two differentially expressed genes should have two peaks and the size of each peak should reflect the proportion of measurements for the corresponding gene. L1000 takes full advantage of this fact by pairing genes optimally, trying to maximize the average difference in their expression levels, and by mixing genes in a 2:1 proportion to enable the assignment of the correct expression levels to each gene within each pair [see @subramanian2017next for the details]. Then it uses the dpeak deconvolution algorithm to detect the peaks within the distribution. This procedure is based on a k-means clustering algorithm that partitions the composite measurements for each profile into $k$ clusters by minimizing the within-cluster sum of squares. It then assigns the largest cluster to the gene with higher bead proportion, and the smallest cluster to the gene with lower bead proportion, assigning their median values to the corresponding gene.
 
The training and testing data consisted of six 384-well perturbagen plates, each containing mutually exclusive sets of compound and short-hairpin (shRNA) treatments (see \nameref{s1-table} and \nameref{s2-table} for a complete list of the perturbagens). Multiple cell lines and perturbagen were to avoid potentially over-fitting to anyone. The compound and shRNA perturbagen plates were arbitrarily grouped into pairs, and to avoid any potential 'information leakage' each pair was profiled in a different cell line. The resulting lysates were amplified by Ligation Mediated Amplification (LMA, @subramanian2017next). The amplicon was then split and detected in both UNI and DUO detection modes, resulting in three pairs of data generated under comparable circumstances.  The training data was available for all the contestants to develop and validate their solutions offline. The testing data was used for submission evaluation during the contest and to populate a live leaderboard. The holdout data was for final evaluation, thus guarding against over-fitting. Prizes were awarded based on performance on the holdout dataset.

The scoring function combined measures of accuracy and computational speed (See \nameref{s1-appendix} for more details). The accuracy metric was the product of two different metrics. The first metric was the average genewise Spearman's rank correlation between the deconvoluted expression values and the ground truth. The second metric was the Area Under the receiver operating curve (AUC) in the prediction of extremely modulated genes. The computational speed was measured as the average runtime in seconds per plate. 

The contest lasted 21 days. A prize purse of $23,000 in cash was offered to competitors as an incentive to be divided among the top 9 submissions.  
<!-- (prize split: 80, 60, 40, 20, 10, 8, 6, 4, and 1 hundred dollars). -->