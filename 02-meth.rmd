# Methods

We provided competitors with a problem statement, access to training and testing data, and a well-defined scoring function. \nameref{figure-1} shows a schematic illustration of these three elements.  

The problem statement described L1000's deconvolution problem and the current solution. The key insight was that the distribution of the composite measurements of two differentially expressed genes should have two peaks and the size of each peak should reflect the proportion of measurements per gene. L1000 takes full advantage of this fact by pairing genes optimally (trying to maximize the average difference in their expression levels) and by mixing genes in a 2:1 proportion to enable the assignment of the correct expression levels to each gene within each pair [see @subramanian2017next for the details]. Then it uses a deconvolution algorithm, called dpeak, that detects the peaks of the distribution and assigns them to each gene. More specifically, the dpeak procedure was based on a k-means clustering algorithm [@lloyd1982least]. This approach partitions the composite measurements for each profile into $k$ clusters by minimizing the within-cluster sum of squares. It then assigns the largest cluster to the gene with higher bead proportion (and the smallest cluster to the gene with lower bead proportion).
 
The training and testing data consisted of six 384-well perturbagen plates, each containing mutually exclusive sets of compound and short-hairpin (shRNA) treatments (see \nameref{s1-table} and \nameref{s2-table} for a complete list of the perturbagens). Multiple treatment types were used to avoid potentially over-fitting to anyone. The compound and shRNA perturbagen plates were arbitrarily grouped into pairs, and to avoid any potential 'information leakage' each pair was profiled in a different cell line. The resulting lysates were amplified by Ligation Mediated Amplification (LMA, @subramanian2017next). The amplicon was then split and detected in both UNI and DUO detection modes, resulting in three pairs of data generated under comparable circumstances.  The training data was available for all the contestants to develop and validate their solutions offline. The testing data was for submission evaluation during the contest and to populate a live leaderboard. The holdout data was for submission final evaluation evaluate, thus guarding against over-fitting. Prizes were awarded based on performance on the holdout dataset.

The scoring function combined measures of accuracy and computational speed (See \nameref{s1-appendix} for more details). The accuracy metric was the product of two different metrics. The first was the average genewise Spearman's rank correlation between the deconvolution gene expressions and the ground truth for each gene. The second was the Area Under the receiver operating curve (AUC) in the prediction of extreme modulated genes. The computational speed was measured as the average runtime in seconds per plate. 

The contest lasted 21 days. A prize purse of $23,000 in cash was offered to competitors as an incentive to be divided among the top 9 submissions (prize split: 80, 60, 40, 20, 10, 8, 6, 4, and 1 hundred dollars).